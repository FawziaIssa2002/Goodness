{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d979643-2721-4c93-86c5-5f2bf7b20bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "from wordcloud import WordCloud\n",
    "import preprocessor as p\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "# from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "# from keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "# from arabic_stemmer import KhojaStemmer\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8191c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import ISRIStemmer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e61c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جذر الكلمة: سعد\n"
     ]
    }
   ],
   "source": [
    "stemmer = ISRIStemmer()\n",
    "\n",
    "def arabic_stemmer(word):\n",
    "    # تقدير الكلمة\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "word = \"سعيدة\"\n",
    "root = arabic_stemmer(word)\n",
    "print(\"جذر الكلمة:\", root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3c7e52-c4ff-4fea-870b-569dad8c8435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مبسوطه</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فرحان</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مستانس</td>\n",
       "      <td>ايجابي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ضايع فارغ</td>\n",
       "      <td>سلبي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تائه</td>\n",
       "      <td>سلبي</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       string   class\n",
       "0      مبسوطه  ايجابي\n",
       "1       فرحان  ايجابي\n",
       "2      مستانس  ايجابي\n",
       "3  ضايع فارغ     سلبي\n",
       "4        تائه    سلبي"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('Sentify_Dataset.xlsx')\n",
    "data = data.astype(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf110306-09d2-4f6d-a658-6dbe9be2af65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "سلبي      259\n",
       "ايجابي    190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2ced15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyarabic.araby import tokenize, strip_tashkeel, strip_tatweel, normalize_ligature\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_arabic_text(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove non-Arabic characters\n",
    "    text = re.sub(\"[^\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDCF\\uFDF0-\\uFDFF\\uFE70-\\uFEFF]+\", \" \", text)\n",
    "    \n",
    "    # Remove tatweel (elongation) characters التكرار\n",
    "    text = strip_tatweel(text)\n",
    "    \n",
    "    # Remove diacritical marks (tashkeel) characters التشكيل\n",
    "    text = strip_tashkeel(text)\n",
    "    \n",
    "     # Remove English characters and numbers\n",
    "    text = re.sub('[A-Za-z0-9]',' ',text)\n",
    "    \n",
    "    # Remove multiple spaces and newline characters\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    \n",
    "    # Normalize alef maksura (ى) to ا\n",
    "    text = re.sub(r'ى', 'ا', text)\n",
    "    \n",
    "    # Normalize teh marbuta (ة) to ه\n",
    "    text = re.sub(r'ة', 'ه', text)\n",
    "    \n",
    "    # Normalize hamza (ء) and alif hamza (أإآ) to ا\n",
    "    text = re.sub(\"[إأآىء]\", \"ا\", text)\n",
    "    \n",
    "    # Normalize waw hamza (ؤ) to و\n",
    "    text = re.sub(r'ؤ', 'و', text)\n",
    "    \n",
    "    # Remove duplicate letters\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "       \n",
    "    # Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "    filtered_words = [word for word in tokens if word.casefold() not in stop_words]\n",
    "    \n",
    "    # Replace emojis\n",
    "    emojis = {\n",
    "        \":)\": \"smile\",\n",
    "        \":(\": \"sad\"\n",
    "        # Add more emoji replacements as needed\n",
    "    }  \n",
    "    filtered_words = [emojis.get(token, token) for token in filtered_words]\n",
    "    \n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af2dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [مبسوطه]\n",
      "1         [فرحان]\n",
      "2        [مستانس]\n",
      "3    [ضايع, فارغ]\n",
      "Name: After_Preprocessing, dtype: object\n",
      "0         [بسط]\n",
      "1         [فرح]\n",
      "2         [انس]\n",
      "3    [ضيع, فرغ]\n",
      "Name: After_Preprocessing, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_clear=data\n",
    "data_clear['After_Preprocessing'] = data['string'].apply(clean_arabic_text)\n",
    "print(data_clear['After_Preprocessing'].iloc[:4])\n",
    "data_clear['After_Preprocessing'] = data_clear['After_Preprocessing'].apply(lambda x: [arabic_stemmer(word) for word in x])\n",
    "print(data_clear['After_Preprocessing'].iloc[:4])\n",
    "data=data_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05efd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix.shape\n",
    "# print('{} Number of tweets has {} words'.format(tfidf_matrix.shape[0], tfidf_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0c9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(tfidf_matrix, data[\"class\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2300ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm,metrics\n",
    "\n",
    "# #Create a svm Classifier\n",
    "# svmclf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# svmclf.fit(X_train, Y_train)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# predicted = svmclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466744f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "# print(\"Accuracuy Score: %\",accuracy_score*100)\n",
    "# print(classification_report(Y_test, predicted, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e0009f-9e04-4436-a3da-8d1e69f85c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " عدد العناصر في المصفوفة الإيجابية: 521\n",
      "{'سوف', 'قدم', 'يرب', 'شجن', 'لكو', 'لقء', 'صطناع', 'وقع', 'غية', 'نجز', 'عام', 'يخب', 'وزر', 'لدي', 'مره', 'ندي', 'ؤلؤ', 'انه', 'اقل', 'تعب', 'خفق', 'وتر', 'او', 'خرج', 'لمة', 'جاز', 'نوم', 'عسل', 'طبع', 'جددد', 'قصة', 'لزم', 'نحي', 'عجب', 'فرص', 'غيم', 'نسب', 'حبب', 'وكأ', 'حمس', 'بسط', 'خمس', 'شىء', 'هو', 'طاييييير🥹🥹🥹🥹', 'ولا', 'وحن', 'اسي', 'لحب', 'اغر', 'قشع', 'منك', 'قلل', 'اصب', 'سرع', 'نشط', 'وعل', 'مع', 'رحم', 'ومم', 'سطو', '💕', 'كبر', 'وضح', 'قدر', 'قمر', 'خفي', 'ضهى', 'وصل', 'وشي', 'حيط', 'وبئ', 'بشق', 'الى', 'وحس', 'اكن', 'كيت', 'على', 'صرح', 'تطع', 'هذا', 'ودة', 'فيش', 'وهم', 'منة', 'خلص', 'تقد', 'غلب', 'مرتاااحه', 'أيم', 'منذ', 'شعع', 'ظني', 'نمء', 'لحظ', 'تسا', 'وقف', 'تدر', 'محب', 'غرم', 'علم', 'شخص', 'سيعانننننننيييييي', 'كرم', 'عده', 'شقت', 'نسى', 'ترا', 'كأن', 'أرد', 'ربي', 'انك', 'خر،', 'فرغ', 'يقن', 'ليك', 'خسر', 'فصح', 'زيد', 'درس', 'قضت', 'دمع', 'قبل', 'فيد', 'عئل', 'اني', 'فرش', 'ميز', 'حاط', 'انا', 'وهب', 'مزج', 'خلا', 'صف،', 'عضو', 'نور', 'يمن', 'معك', '،الحمدلله', 'لرب', 'بذن', 'بك', 'كل', 'ف', 'صحء', 'سبع', 'سطر', 'حقق', 'فوق', 'عظم', 'منى', 'جمع', 'عتم', 'هيت', 'صبه', 'خطه', 'رفه', 'امي', 'حله', 'حيه', 'اين', 'برب', 'تجن', 'دنة', 'عجز', '٢', 'حربش', 'متن', 'جئع', 'الظ', 'سرر', 'بسم', 'شي', 'لفظ', 'ورج', 'اعط', 'تمم', 'ورش', 'سلم', 'وحش', 'وقت', 'قوه', 'جتع', 'سرق', 'عبث', 'نبض', 'تخف', 'صبر', 'اطر', 'بس', 'عبدالل', 'بأن', 'لغد', 'اليه', 'تحمس', 'صبح', 'شوكولاته', 'حفل', 'كان', 'عبر', 'دون', 'رحه', 'رضى', 'هذه', 'رحة', 'خصه', 'قلب', 'الذي', 'بطمأنينة', 'كمل', 'رفرف', 'ربك', 'سمء', 'عها', 'ذكر', 'خلق', 'خلف', 'عين', 'بصديقاتي', 'اصغ', 'حظة', 'صغر', 'نجح', 'كبييير،', 'لصت', 'جلل', 'رضا', 'ستب', 'كانت', 'يدي', 'انن', '❤️❤️❤️❤️', 'متع', 'رجع', 'بدع', 'نعم', 'جدا', 'قوة', 'ضغط', 'خفة', 'حظ', 'فرحههههه', '؟', 'حاسيس', 'بعد', 'سعه', 'لله', 'ليه', 'اخر', 'عبئ', 'فائل', 'حبة', 'وجد', 'ذلك', 'سعد', 'طلبو', 'دور', 'عصف', 'ولكن', 'ابي', 'خزل', 'له', 'رخء', 'يأت', 'يوم', 'جي،', 'كتب', 'اي', 'ييع', 'فوز', 'فضل', 'كلم', 'امر', 'قهت', 'نهر', 'كشف', 'حب', 'يدق', 'نظر', 'كبيييرررر', 'حسن', 'حمدلل', 'ات', 'ولل', 'حين', 'بعه', 'صديقاتي،', 'وأصدقائي...', 'لم', 'كنت', 'دعم', 'سيع', 'يلى', 'فرح', 'احس', 'عقد', 'طاييييير', 'عهم', 'وفق', 'بكر', 'جهز', 'عقرب', 'قرر', 'نفس', 'عرف', 'وجه', 'ارك', 'لنا', 'شاءلل', 'قرب', 'لطق', 'صدق', 'لي', 'رغم', 'يا', 'روح', 'جمل', 'ذكء', 'شدد', 'رب', 'اظن', 'دنا', 'رغب', 'حنو', 'يلق', 'دوسر', 'أكد', 'طمأ', 'وبي', 'بيت', 'قيس', 'جدد', 'واعتزازي', 'كثر', 'به', 'اول', 'حول', 'مش', 'لو', 'كوس', 'رطب', 'لطف', 'امل', 'عند', 'عني', 'تفهم', 'قوس', 'ايا', 'عدي', 'حجت', 'شكر', 'تئه', 'الن', 'عمق', '١٢', 'حلوووه🤍', 'وحل', 'و', 'غمر', 'ريح', 'بحياتي🥹🥹🥹', 'جدا💖💖💖💖💖💖💖', 'دوم', 'خلب', 'كلة', 'لشد', 'منه', 'ان', 'صير', 'حيت', 'رفق', 'جلك💖💖', 'خبط', 'وكن', 'ما', 'فين', 'أهل', 'لا', 'معي', 'ليا', 'ترم', 'يزي', 'حية', 'وحو', 'أسعى', 'طمن', 'حال', 'ذ', 'لقد', 'بها', 'نصر', 'تجه', 'ريق', 'جدف', 'الا', 'لمس', 'قرقيع', 'عن', 'ارد', 'من', 'شرع', 'لهف', 'عيد', 'تأكد', 'غرب', 'بغه', 'عبد', 'عدء', 'ب', 'يكن', '..', 'بشت', 'عنه', 'مني', 'يقظ', 'فخر', 'بهم', 'وحب', 'بين', 'وحد', 'فقد', 'هما', 'غفر', 'عضء', 'شمس', 'جرم', 'تقت', 'رأت', 'دنيااااا', 'سبي', 'مو', 'بدي', 'سكن', 'بشر', 'حدي', 'يفز', 'درى', 'طير', 'الل', 'اشب', 'كله', 'فصل', 'اهل', 'بهج', 'فيه', 'بدن', 'بخر', 'رتح', 'سلذ', 'صوم', 'فرج', 'لها', 'حبق', 'زي', 'احب', 'طمح', 'لان', 'ذهب', 'رحب', 'عمل', 'وبد', 'علك', 'عنقود', 'لكن', 'في', 'علق', 'شعر', 'امت', 'شهر😍😍😍😍😍', 'انس', 'لمت', 'به،', 'فتر', 'جزت', 'أحبائ', 'شهر', 'حمدالل', 'وبن', 'حرق', 'لقب', 'سبب', 'دحي', '،', 'معا', 'للي', 'رمض', 'بكل', 'ولت', 'وتم', 'لكل', 'انت', 'سند', 'شوق', 'عصب', 'دخل', 'لن', 'التي', 'ناس', 'فعل', 'تمت', 'زمن', 'كفي', 'بغر', 'مششششش', 'اعش', 'كتيير', 'لك', 'حجة', 'ونا', 'بما', 'طمئ', 'رزق', 'لجن', 'حمد', '💓💓', 'اليوم', 'امن', 'لرؤ', 'تدي', 'مهم', 'شيء'}\n",
      " عدد العناصر في المصفوفة السلبية: 696\n",
      "{'ونت', 'بحج', 'سوف', 'دكتر', 'تقلب', 'يصر', 'قدم', 'أغدر', 'يرب', 'اخف', 'بقء', 'منها', 'ء', 'وقع', 'سؤل', 'غية', 'نجز', 'أبعد', 'همم', 'حذر', 'بعثر', 'سئل', 'وكل', 'جد..', 'حقه،', 'لدي', 'مره', 'ندي', 'وعش', 'انه', 'اقل', 'تعب', 'وتر', 'طلع', 'او', 'خرين،', 'ماك', 'خرج', 'دمر', 'جاز', 'غرق', 'طبع', 'عرم', 'كأس', 'مر', 'اصح', 'جفن', 'امه', 'كسر', 'حاج', 'عدم', 'أقم', 'عصبب', 'سقط', 'كفو', 'أخر', '١٧', 'اسف', 'ليس', 'لطز', 'وكأ', 'حمس', 'هدوء.', 'حبط', 'ابك', 'طقت', 'شىء', 'هو', 'رضي', 'جدر', 'حدث', 'ولا', 'اسي', 'هخخ', 'اشخ', 'ذبذب', 'ببل', 'حرم', 'وفة', 'اصييييييح', 'كوكييز', 'جزء', 'تغلق', 'خير', 'عدل', 'متى', 'ضرر', 'نحل', 'قرب،', 'ليء', 'سرع', 'تجد', 'مع', 'غضب', 'ثمل', 'سنن', 'كاف', 'أحلام', 'كبر', 'خرق', 'هالفتر', 'عبء', 'شلع', 'بغى', 'لسب', 'قدر', 'خفي', 'بلغ', 'وصل', 'يكون', 'سيء', 'صدقائ', 'حيط', 'ادة', '٥', 'قل', 'سهم', 'الى', 'اكن', 'بنت', 'ام', 'على', 'لهم', 'هوجاء', 'لصح', 'تحز', 'اخاااااف', 'طيل', 'نكن', 'حي', 'ارض', 'بد.', 'حلي', 'هذا', 'قادرررره', 'عقل', 'إنجاز', 'خلص', 'صمتي،', 'حسي', 'غلب', 'تقي', 'يضء', 'ظني', 'جرت', 'غدر', 'تلك', 'ركض', 'رهق', 'سفر', 'نهي', 'نهك', 'طعم', 'علم', 'شخص', 'شرح', 'شبع', 'فشل', 'وأد', 'شبتر', 'سر', 'فرط', 'ادف', 'فرق', 'كأن', 'تخذ', 'زقة', 'أرد', 'ربي', 'انك', 'حسب', 'فرغ', 'قاسية،', 'خسر', 'صعب', 'درس', 'ذنب', 'جلس', 'دمع', 'اتم', 'تهر', 'قبل', 'اني', 'انا', 'جاي', 'غلف', 'حنى', 'وري', 'يمك', 'دهر', 'اعجب', 'ومن', 'وسف', 'كما', 'طفئ', 'سيطر', 'مرة', 'كل', 'بشء', 'شعب', 'جسد', 'سخط', 'ففف', 'ادر', 'جبت', 'حقق', 'واد', 'دقت', 'كمه', 'فوق', '\"عادي\"', 'صلح', 'هلع', '؟؟كيف', 'تمل', 'جمع', 'يجب', 'عليل.', 'حيه', 'رعب', 'اقدر', 'عاد', 'عجز', 'جئع', 'عدة', 'حلق', 'ماب', 'دري', 'قرن', 'لست', 'ضلع', 'سبق', 'شي', 'اعط', 'عسى', 'عتو', 'ورش', 'ضمر', 'سلم', 'غمم', 'بدو', 'وقت', 'زعل', 'بكف', 'جفء', 'فلم', 'صبر', 'تكر', 'ذار', 'بس', 'سوى', 'بأن', 'ـغرب', 'لغد', 'طفل', 'خيس', 'حوي', 'عهد', 'غرف', 'طقي', 'دا', 'وعف', 'كمثل', 'كان', 'شعل', 'شيل', 'عزل', 'دون', 'وي', 'قلع', 'ولم', 'هذه', 'سنة', 'رهق،', 'اهخ', 'يفق', 'جهل', 'قلب', 'كمل', 'قتل', 'هجر', 'سمء', 'جزئ', 'وضع', 'أبتلع', 'ظهر', 'رمضان.', 'يدك', 'ذكر', 'خلق', 'لعن', 'غطه', 'صدع', 'سيئ', 'مايصير', 'نجح', 'حمقى', 'خطى', 'راكم،', 'كمة', 'وحق', 'طن،', 'رهه', 'الي', 'كانت', 'حلم', 'انن', 'رجع', 'تحم', 'قاع', 'غيهب', 'طقة', 'جاب', 'رسي', 'جدا', 'خبئ', 'نقم', 'ضغط', 'تشت', 'Confused', 'جرح', 'درج', 'انحل', 'سقم', 'غلط', '؟', 'بعد', 'خوف', 'وجد', 'ذلك', 'سعد', 'هالاسبوع', 'عصف', 'ابي', 'ولكن', 'له', 'يأت', 'يوم', 'القى', 'لما', 'كتب', 'عطو', 'يطق', 'اي', 'برق', 'بدت', 'فضل', 'قلق', 'كلم', 'امر', 'غلق', 'طوه', 'نهر', 'اقد', 'شكل', 'حب', 'مات', 'انهزامي،', 'اجد', 'صدر', 'جبر', 'ترميييييييننن', 'ضايق', 'نظر', 'ولل', 'اما', 'حين', 'مستقبلية', 'بان', 'ريب', 'كئب', 'ايش', 'بهت', 'لأن', 'سمع', 'لم', 'تحدث', '.', 'قشعر', 'مال', 'صفر', 'حرب', 'ضيع', 'فرح', 'احس', 'موت', 'ويش', 'شتت', 'سرب', 'بئر', 'تطل', 'ملأ', 'ثقل', 'جيب', 'قوي', 'كر؟', 'قرر', 'نفس', 'هكه', 'عرف', 'رهب', 'حدد', 'فالهزيمة', 'وجه', 'هل', 'علي', 'ليل', 'يسر', 'طيق', 'وجا', 'قرب', 'جوع', 'صدق', 'لي', 'ضيق', 'ثق،', 'رغم', 'مواعيد', 'روح', 'يفد', 'نرفز', 'شدد', 'جية', 'رغب', 'دنا', 'صح', 'خبأ', 'ضعف', 'اطلع', 'ختباء،', 'ماض', 'فات', 'حبس', 'انم', 'بيت', 'جدد', 'ضيل.', 'محتجب،', 'كثر', 'وخل', 'فكان', 'الأ', 'اول', 'كذ،', 'حول', 'مش', 'جسم', 'وسن', 'امل', 'ارى', 'عني', 'عند', 'خنق', 'يضببببطططططططط!!!!!!!!', 'ستء', 'غصة', 'ينا', 'عدي', 'يعد', 'خوء', 'تئه', 'عمق', 'عنق', 'عطب،', 'و', 'رقق', 'كلة', 'ان', 'شغل', 'حطت', 'بقم', 'كيف', 'خبط', 'صمت', 'ما', 'فين', 'أصل', 'ملي', 'وخب', 'هزل', 'عمة', 'ضرب', 'اكر', 'لا', 'معي', 'برا', 'بصم', 'ترم', 'خصم', 'جعل', 'حط', 'واستعداد', 'حية', 'هم', 'شيط', 'وسط', 'خدم', 'ارخ', 'قعد', 'كوكيز', 'ومانعارفه', 'حال', 'بها', 'نصر', 'زدد', 'قوم', 'بلع', 'الا', 'طول', 'معصصصببة', 'كره', 'خبر', 'رأس', 'عن', 'ارد', 'الم', 'من', 'طيع', 'اضي', 'شرع', 'داعي،', 'عيد', 'فكر', 'غرب', 'اسء', 'نقذ', 'حسس', '..', 'عنه', 'مني', 'وش', 'فعم', 'شته', 'قيد', 'جنت', 'تحد', 'ضير', 'ابد', 'شيئ', 'خئف', 'ونس', 'بكء', 'غمض', 'يفو', 'تطي', 'رور', 'ايم', 'حزن', 'ايد', 'نهء', 'طرق', 'بين', 'طلب', 'هزم', 'لقى', 'وحد', 'طىء', 'ثانوية،', 'فسق', 'فقد', 'غفر', 'وزد', 'زجاااج', 'اذا', 'رأت', 'لظل', 'وسع', 'مو', 'احد', 'بحث', 'بشر', 'اوف', 'شبو', 'هرب', 'بدأ', 'تكئ', 'الل', 'خيب', 'اخذ', 'كله', 'اهل', 'فيه', 'نفذ', 'أنب', 'اثب', 'بدن', 'عرص', 'غير', 'أعجز', 'لني', '😢', 'سننجو؟؟؟', 'انهزامية', 'بصح', 'هئل', 'زي', 'نشق', 'مايرتفع', 'ثلث', 'احب', 'طفي', 'خيف', 'غذء', 'دائ', 'خلت', 'عمل', 'وبد', 'أحس', 'وأن', 'نصف', 'علك', 'هناك', 'لكن', 'حيل', 'في', 'متضاييييييييقه', 'نقص', 'طز', 'جوف', 'علق', 'شعر', 'ثقة', 'ردد،', 'انس', 'حزن؟', 'عليها', 'شهر', 'ودع', 'صار', 'ننى', 'حرق', 'خاف', 'سبب', '،', 'وصف', 'رمض', 'بكل', 'اسك', 'اقى', 'جمد', 'انت', 'اعز', 'وين', 'اكف', 'شوق', 'ميد', 'توتر', 'خذل', 'لفل', 'باشمئزاز', 'صفح', 'دكتور', 'همة', 'ذلالي!', 'عصب', 'هدي', 'ألف', 'دخل', 'شتم', 'نزع', 'صرخ', 'لن', 'شغف', 'وما', 'ناس', 'درم', 'كفي', 'زمن', 'بقي', 'سير', 'وضى', 'عدت', 'حجة', 'ونا', 'يلي', 'واح', 'رزق', 'هلل', 'ياء', 'ودي', 'لحق', 'صرف', 'اليوم', 'رحل', 'حمل', 'امن', 'انع', 'تخل', 'قد', 'مب', 'لنه', 'غلل', 'شيء', 'امش', 'جنن', 'صحح'}\n"
     ]
    }
   ],
   "source": [
    "positive_words = set()\n",
    "negative_words = set()\n",
    "\n",
    "for index, comment in data.iterrows():\n",
    "    if comment[\"class\"] == \"ايجابي\":\n",
    "        positive_words.update(comment[\"string\"].split())\n",
    "    elif comment[\"class\"] == \"سلبي\":\n",
    "        negative_words.update(comment[\"string\"].split())\n",
    "\n",
    "cleaned_positive_words = set()\n",
    "for word in positive_words:\n",
    "    cleaned_positive_words.add(arabic_stemmer(word))\n",
    "positive_words=cleaned_positive_words\n",
    "\n",
    "num_words1 = len(positive_words)\n",
    "print( \" عدد العناصر في المصفوفة الإيجابية:\", num_words1)\n",
    "print(positive_words)\n",
    "\n",
    "cleaned_negative_words = set()\n",
    "for word in negative_words:\n",
    "    cleaned_negative_words.add(arabic_stemmer(word))\n",
    "negative_words=cleaned_negative_words\n",
    "\n",
    "num_words = len(negative_words)\n",
    "print( \" عدد العناصر في المصفوفة السلبية:\", num_words)\n",
    "print(negative_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e1f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " عدد العناصر في المصفوفة الإيجابية: 681\n",
      "{'سوف', '🥳', 'قدم', 'يرب', 'شجن', 'لكو', 'لقء', 'صطناع', 'وقع', '💐', 'غية', 'نجز', 'فؤل', 'همم', 'عام', 'يخب', 'وزر', '🍨', 'لدي', 'مره', 'ندي', 'ؤلؤ', 'انه', 'اقل', 'تعب', 'خفق', 'وتر', '✨', 'او', 'ثبر', 'خرج', 'لمة', 'متز', 'جاز', 'نوم', 'عسل', 'طبع', 'جددد', 'قصة', 'مرح', 'لزم', 'نحي', 'شرق', 'عجب', 'ثير', '🍴', 'فرص', 'هنا', 'جذب', 'غيم', 'نسب', 'حبب', '💝', 'وكأ', 'حمس', 'بسط', 'خمس', 'شىء', 'هو', 'طاييييير🥹🥹🥹🥹', 'سلى', 'ولا', 'وحن', '🌹', 'اسي', 'لحب', 'وئم', '🥰', 'بهء', 'اغر', '🍸', 'قشع', '😏', 'منك', '🤎', '🍦', 'قلل', 'اصب', 'سرع', 'نشط', '😋', 'وعل', 'مع', 'رحم', '🍫', 'ومم', 'سطو', '💕', 'كبر', '🎆', 'عزة', 'وضح', 'قدر', 'قمر', 'خفي', 'ضهى', 'وصل', '🌟', 'وشي', 'حيط', 'وبئ', 'بشق', 'الى', 'وحس', 'اكن', ':)', 'كيت', 'على', 'لهم', 'ماع', '🥄', 'صرح', '🌷', '🥡', '🍡', 'تطع', '🥂', 'هذا', 'ودة', '🌼', 'فيش', '🥤', 'وهم', 'منة', 'خلص', 'تقد', '👍', 'غلب', '😁', 'مرتاااحه', 'أيم', 'منذ', 'شعع', 'ظني', 'نمء', '⭐️', 'لحظ', '🍶', 'تسا', 'وقف', 'تدر', 'محب', 'غرم', 'علم', 'شخص', '💗', 'سيعانننننننيييييي', 'كرم', 'عده', '💫', 'شقت', 'نسى', 'ترا', '😄', 'كأن', 'حفز', 'أرد', 'ربي', 'انك', '🎉', 'خر،', 'فرغ', 'يقن', 'ليك', 'خسر', 'فصح', 'زيد', '🎀', 'درس', 'قضت', 'دمع', 'قبل', '🎈', 'فيد', 'عئل', 'اني', 'فرش', 'ميز', 'حاط', 'انا', 'وهب', '🌻', '🍺', 'مزج', '😂', '🍷', 'خلا', 'صف،', 'نعش', '🌺', 'عضو', '☕️', 'نور', 'يمن', 'معك', '،الحمدلله', 'لرب', 'بذن', 'بك', 'كل', 'ف', 'صحء', '💞', 'سبع', 'سطر', '😿', 'حقق', '💙', 'فوق', 'عظم', 'منى', 'جمع', '🎊', 'عتم', 'يجب', 'هيت', 'صبه', 'خطه', 'رفه', 'مجد', '🧁', 'امي', '😇', 'حله', 'حيه', 'اين', 'برب', 'تجن', 'دنة', '😅', 'عجز', '٢', 'حربش', 'متن', 'جئع', 'الظ', 'سرر', 'بسم', 'شي', 'لفظ', 'ورج', 'اعط', 'تمم', 'ورش', 'سلم', 'وحش', 'وقت', 'حنن', '☀️', 'قوه', 'جتع', 'سرق', '🍾', 'عبث', 'نبض', 'تخف', 'صبر', 'اطر', 'بس', 'عبدالل', 'بأن', 'لغد', 'اليه', '😹', '🍪', 'تحمس', 'صبح', 'شوكولاته', 'حفل', 'كان', 'عبر', '🍹', 'دون', 'رحه', 'رضى', 'هذه', 'رحة', 'خصه', '🥛', 'قلب', 'الذي', 'بطمأنينة', 'كمل', 'رفرف', 'ربك', 'سمء', 'وضع', 'عها', 'ذكر', 'خلق', 'خلف', 'عين', 'بصديقاتي', 'اصغ', 'حظة', 'صغر', 'نجح', 'كبييير،', 'لصت', '😻', 'جلل', 'رضا', 'ستب', 'كانت', '🤍', '😸', 'يدي', 'انن', '❤️❤️❤️❤️', 'متع', 'رجع', 'بدع', 'نعم', 'جدا', 'قوة', 'ضغط', 'خفة', 'حظ', 'فرحههههه', '؟', 'حاسيس', 'بعد', '💟', 'سعه', 'لله', 'ليه', '🌈', 'اخر', 'عبئ', 'فائل', 'حبة', 'وجد', 'ذلك', 'سعد', 'طلبو', 'دور', 'عصف', 'ولكن', 'ابي', 'خزل', 'له', 'رخء', 'يأت', 'يوم', 'جي،', 'كتب', 'اي', 'ييع', 'برق', 'فوز', 'فضل', 'كلم', 'امر', 'قهت', 'نهر', 'كشف', 'حب', 'جرأ', 'يدق', 'نظر', 'كبيييرررر', 'حسن', '🖤', 'حمدلل', 'ات', 'ولل', 'حين', '🙀', '🎁', '😉', 'بعه', 'صديقاتي،', '🍥', 'وأصدقائي...', 'لم', 'كنت', 'دعم', '🙌', '🍽', 'سيع', 'يلى', 'فرح', 'احس', 'عقد', '🎇', 'طاييييير', 'عهم', 'وفق', 'بكر', 'جهز', 'عقرب', 'قرر', '😃', 'نفس', 'عرف', 'وجه', 'ارك', 'لنا', '💯', 'يسر', 'شاءلل', 'قرب', 'لطق', 'صدق', 'لي', 'رغم', 'يا', 'روح', ':D', 'جمل', 'ذكء', 'شدد', '😆', 'رب', 'اظن', '😼', 'دنا', 'رغب', 'حنو', 'يلق', 'دوسر', '🥢', 'جهد', 'أكد', 'طمأ', '🤗', '🍰', 'وبي', 'بيت', 'وفء', 'قيس', '👏', 'جدد', 'واعتزازي', 'كثر', 'به', 'ألق', 'اول', 'حول', 'مش', 'لو', 'كوس', 'رطب', 'لطف', 'امل', 'عند', 'عني', 'تفهم', 'قوس', 'ايا', 'عدي', 'حجت', 'شكر', '😺', 'تئه', 'تعة', 'الن', '🔥', 'عمق', '١٢', 'حلوووه🤍', '🍵', 'وحل', 'و', 'غمر', 'ريح', 'بحياتي🥹🥹🥹', 'جدا💖💖💖💖💖💖💖', 'دوم', '💓', 'خلب', 'كلة', '💜', 'لشد', 'منه', 'ان', 'صير', 'خيل', 'حيت', 'رفق', 'جلك💖💖', 'خبط', 'هنء', 'وكن', 'ما', 'فين', '😊', '😚', 'أهل', '💛', '😎', 'لا', 'معي', 'ليا', 'ترم', '❤️', 'يزي', 'حية', 'وحو', '🤣', 'أسعى', '🍭', '😘', 'طمن', '🤩', 'حال', 'ذ', 'لقد', 'بها', 'نصر', 'تجه', 'ريق', '🍧', 'جدف', 'الا', '🍻', 'لمس', 'قرقيع', '🧡', 'عن', 'رئع', 'ارد', 'من', 'رضو', 'شرع', 'لهف', 'عيد', 'تأكد', 'تطر', 'غرب', 'فكر', 'بغه', 'عبد', 'عدء', 'ب', 'يكن', '..', 'بشت', 'عنه', 'مني', 'ثرة', 'يقظ', 'فخر', 'صفء', 'بهم', '❤️\\u200d🔥', 'برك', 'وحب', '😗', 'بين', 'وحد', '😌', 'فقد', 'هما', 'غفر', 'عضء', 'شمس', 'جرم', 'تقت', 'رأت', 'دنيااااا', 'حيي', 'سبي', 'مو', 'بدي', 'سكن', 'بشر', '🍬', 'حدي', 'يفز', 'درى', '❣️', 'طير', 'الل', 'اشب', 'كله', 'فصل', 'اهل', 'بهج', 'فيه', 'تمز', '🍩', 'بدن', 'بخر', 'رتح', 'غير', 'سلذ', 'صوم', 'فرج', 'زدهار', 'لها', 'حبق', 'زي', 'احب', 'طمح', 'لان', 'ذهب', 'رحب', 'عمل', 'وبد', '☺️', 'علك', 'عنقود', '🥣', 'لكن', 'في', 'علق', 'شعر', 'ثقة', 'امت', 'شهر😍😍😍😍😍', 'انس', 'لمت', 'به،', '🌞', '🎂', 'فتر', 'جزت', 'أحبائ', '💖', 'شهر', 'حمدالل', 'وبن', 'حرق', 'لقب', 'سبب', 'دحي', '،', 'تحس', 'معا', '😍', 'للي', 'رمض', 'بكل', 'ولت', 'وتم', 'لكل', 'انت', 'سند', 'شوق', '🌸', 'عصب', 'دخل', 'لن', '💚', 'التي', 'شغف', 'ناس', 'فعل', 'تمت', 'زمن', 'كفي', 'بغر', 'مششششش', '🙂', '😙', 'اعش', 'كتيير', '😽', 'لك', 'حجة', 'ونا', 'بما', 'شجع', 'طمئ', 'رائع ', 'رزق', 'لجن', 'حمد', '💓💓', '😾', 'اليوم', 'امن', 'حمل', '💘', 'لرؤ', '🍼', 'تدي', 'وزن', 'مهم', 'شيء'}\n"
     ]
    }
   ],
   "source": [
    "new_positive_words = [ \"سعيد\", \"رائع\", \"ممتاز\", \"مبهج\", \"محبب\",  \"مفرح\", \"جميل\", \"مبتهج\", \"مبهج\", \"مبسوط\", \"سرور\", \"نجاح\", \"إبداع\", \"ملهم\", \"مرح\",  \"سلام\", \"ثقة\", \"أمل\", \"تفاؤل\", \"إثارة\",\n",
    "    \"مبارك\", \"فرحان\", \"بهجة\", \"تحفيز\", \"مبتهج\",\"انتصار\", \"سعادة\", \"رضا\", \"تميز\", \"استمتاع\", \"محبة\", \"تألق\", \"مغامرة\", \"تقدم\", \"تميز\", \"متعة\", \"إنجاز\", \"فخر\", \"تحسين\", \"مثير\",\"اهتمام\", \"مميز\", \"سلوى\", \"تشجيع\", \"إنجاز\",\n",
    "    \"تميز\", \"تفاؤل\", \"اشراقة\", \"سرور\", \"حب\",\"بهجة\", \"راحة\", \"انتعاش\", \"بهاء\", \"هناء\",\"متعة\", \"عزة\", \"بهجة\", \"فرح\", \"تشجيع\",\n",
    "    \"حب\", \"انتصار\", \"بهجة\", \"تحفيز\", \"تميز\",\"انتعاش\", \"تألق\", \"فرحة\", \"اكتشاف\", \"متعة\",   \"نجاح\", \"سرور\", \"حيوية\", \"تحفيز\", \"احتفال\",  \"تميز\", \"رضا\", \"سعادة\", \"حب\", \"تشجيع\",\n",
    "    \"تفاؤل\", \"ثقة\", \"تألق\", \"انتعاش\", \"سرور\",  \"راحة\", \"هناء\", \"بهاء\", \"انتصار\", \"فرحة\",\n",
    "    \"سعادة\", \"رضا\", \"تحفيز\", \"اكتشاف\", \"إنجاز\", \"سلام\", \"ثقة\", \"أمل\", \"تفاؤل\", \"إثارة\",\n",
    "    \"حيوية\", \"بهاء\", \"نجاح\", \"استمتاع\",\"تألق\",\"تميز\", \"استمتاع\", \"سلام\", \"حب\", \"تفاؤل\",\n",
    "    \"راحة\", \"سرور\", \"انتصار\", \"اكتشاف\", \"فرحة\",\"سعادة\", \"رضا\", \"تحفيز\", \"نجاح\", \"إنجاز\",\n",
    "    \"حيوية\", \"هناء\", \"بهاء\", \"انتعاش\", \"إثارة\", \"بهجة\", \"تألق\", \"ثقة\", \"مثير\", \"إبداع\",\n",
    "    \"تشجيع\", \"تمييز\", \"مميز\", \"سلوى\", \"عزة\", \"رضوان\", \"تقدم\", \"تحفيز\", \"سعادة\", \"رفاهية\",\n",
    "    \"إنجازات\", \"سرور\", \"فرح\", \"سعادة\", \"رضا\", \"بهجة\", \"سرور\", \"تحفيز\", \"فخر\", \"تألق\",\n",
    "    \"إثارة\", \"سلام\", \"تميز\", \"تشجيع\", \"متعة\", \"سرور\", \"رضا\", \"تحفيز\", \"تألق\", \"سعادة\",\n",
    "    \"انتعاش\", \"حب\", \"تفاؤل\", \"اكتشاف\", \"متعة\", \"فرح\", \"سلام\", \"تميز\", \"سرور\", \"رضا\", \"تحفيز\", \"تألق\", \"سعادة\", \"انتعاش\", \"بهجة\", \"سعادة\", \"رضا\", \"تحفيز\", \"فرح\", \"نجاح\",\n",
    "    \"اكتشاف\", \"سرور\", \"تفاؤل\", \"حب\", \"تميز\", \"إثارة\", \"فرح\", \"سعادة\", \"رضا\", \"تحفيز\", \"تألق\", \"سرور\", \"تفاؤل\", \"اكتشاف\", \"بهجة\",\n",
    "    \"حب\", \"فرح\", \"تحفيز\", \"سعادة\", \"إنجاز\",  \"راحة\", \"انتعاش\", \"بهجة\", \"سلام\", \"سعادة\",   \"تحفيز\", \"إثارة\", \"إلهام\", \"تفاؤل\", \"إنجاز\",   \"تميز\", \"تحسين\", \"تطور\", \"تقدم\", \"تحقيق\", \"ابتهاج\", \"إشراق\", \"انتصار\", \"تألق\", \"ازدهار\", \"استمتاع\", \"ايجابية\", \"أمل\", \"بريق\", \"بهجة\", \"تفاؤل\", \"ثقة\", \"جمال\", \"حب\", \"حيوية\",  \"خيال\", \"راحة\", \"سرور\", \"سعادة\", \"شغف\",\"صفاء\", \"فرح\", \"فخر\", \"قوة\", \"كرم\",\"محبة\", \"متعة\", \"مثابرة\", \"مجد\", \"مباركة\",\n",
    "    \"متفائل\", \"نجاح\", \"نشاط\", \"هناء\", \"هنا\",  \"وجداني\", \"وفاء\", \"وئام\", \"يقين\", \"يسر\",  \"إبتسامة\", \"تألق\", \"تحقيق\", \"تحفيز\", \"تحمل\",  \"تعلم\", \"تغيير\", \"تقدير\", \"توازن\", \"تواضع\",  \"ثقة\", \"جاذبية\", \"جرأة\", \"حب\", \"حنان\",\n",
    "    \"حيوية\", \"خيال\", \"راحة\", \"سعادة\", \"شغف\", \"صبر\", \"فرح\", \"فكر\", \"قوة\", \"كرم\", \"محبة\", \"مثابرة\", \"مجد\", \"مجتهد\", \"مستقبل\", \"نجاح\", \"هناء\", \"وفاء\", \"يقين\", \"يسر\",\"إبتسامة\", \"تألق\", \"تحقيق\", \"تحفيز\", \"تحمل\",\n",
    "    \"تعلم\", \"تغيير\", \"تقدير\", \"توازن\", \"تواضع\", \"ثقة\", \"جاذبية\", \"جرأة\", \"حب\", \"حنان\", \"حيوية\", \"خيال\", \"راحة\", \"سعادة\", \"شغف\", \"صبر\", \"فرح\", \"فكر\", \"قوة\", \"كرم\", \"محبة\", \"مثابرة\", \"مجد\", \"مجتهد\", \"مستقبل\",\n",
    "    \"نجاح\", \"هناء\", \"وفاء\", \"يقين\", \"يسر\",  \"إبتسامة\", \"تألق\", \"تحقيق\", \"تحفيز\", \"تحمل\",  \"تعلم\", \"تغيير\", \"تقدير\", \"توازن\", \"تواضع\",  \"ثقة\", \"جاذبية\", \"جرأة\", \"حب\", \"حنان\",   \"حيوية\", \"خيال\", \"راحة\", \"سعادة\", \"شغف\",   \"صبر\", \"فرح\", \"فكر\", \"قوة\", \"كرم\",  \"محبة\", \"مثابرة\", \"مجد\", \"مجتهد\", \"مستقبل\", \"نجاح\", \"هناء\", \"وفاء\", \"يقين\", \"يسر\" , \"جميلة\" ,\"رائع \"\n",
    "]\n",
    "positive_smileys = [\":)\", \":D\", \"😊\", \"😄\", \"😃\", \"🙂\", \"😎\", \"👍\", \"💖\", \"🌟\", \"🎉\", \"🥳\", \"🤩\", \"😍\", \"😁\", \"👏\", \"🙌\", \"🥰\", \"🤗\", \"🌹\",\n",
    "                   \"😁\", \"😄\", \"😆\", \"😊\", \"😋\", \"😍\", \"😎\", \"🤗\", \"😇\", \"🥰\", \"😂\", \"🤣\", \"😃\", \"😄\", \"😅\", \"😆\", \"😉\", \"😊\", \"😋\",\n",
    "                     \"😌\", \"😍\", \"😘\", \"🥰\", \"😗\", \"😙\", \"😚\", \"☺️\", \"🙂\", \"🤩\", \"😏\", \"😻\", \"😺\", \"😸\", \"😹\", \"😼\", \"😽\", \"🙀\", \"😿\", \"😾\",\n",
    "                     \"💖\", \"💗\", \"💘\", \"💝\", \"💞\", \"💕\", \"❤️‍🔥\", \"💓\", \"❣️\", \"💟\", \"💗\", \"💕\", \"💖\", \"💓\", \"💞\", \"💘\", \"💝\", \"❤️\", \"🧡\", \"💛\",\n",
    "                     \"💚\", \"💙\", \"💜\", \"🤎\", \"🖤\", \"🤍\", \"💯\", \"🔥\", \"✨\", \"🌟\", \"💫\", \"⭐️\", \"🌈\", \"☀️\", \"🌞\", \"🌻\", \"🌼\", \"🌸\", \"💐\", \"🌷\", \n",
    "                     \"🌹\", \"🌺\", \"🌞\", \"🌈\", \"🎉\", \"🎈\", \"🎊\", \"🎇\", \"🎆\", \"🎀\", \"🎁\", \"🎂\", \"🍰\", \"🧁\", \"🍦\", \"🍨\", \"🍧\", \"🍡\", \"🍥\", \"🍬\", \n",
    "                     \"🍭\", \"🍫\", \"🍪\", \"🍩\", \"🥂\", \"🍾\", \"🍷\", \"🍸\", \"🍹\", \"🍺\", \"🍻\", \"🥤\", \"🥛\", \"🍼\", \"☕️\", \"🍵\", \"🍶\", \"🍵\", \"🥄\", \"🍴\", \"🍽\",\n",
    "                     \"🥣\", \"🥡\", \"🥢\", \"🥢\", \"🥢\"]\n",
    "\n",
    "\n",
    "stemmed_positive_words = []\n",
    "for word in new_positive_words:\n",
    "    stemmed_word = clean_arabic_text(word)\n",
    "    stemmed_word = arabic_stemmer(word)\n",
    "    stemmed_positive_words.append(stemmed_word)\n",
    "\n",
    "new_positive_words=stemmed_positive_words\n",
    "# print(new_positive_words)\n",
    "positive_words = positive_words.union(new_positive_words)\n",
    "positive_words = positive_words.union(positive_smileys)\n",
    "num_words1 = len(positive_words)\n",
    "print( \" عدد العناصر في المصفوفة الإيجابية:\", num_words1)\n",
    "print(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eacfe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = ['لا', 'لم', 'لن', 'ما', 'ليس', 'بدون', 'غير', 'أبداً', 'لن يكون']\n",
    "def contains_negative_words(text):\n",
    "    for word in bad_words:\n",
    "        if word in text:\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf58ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " عدد العناصر في المصفوفة negative: 773\n",
      "{'ونت', 'بحج', 'سوف', 'دكتر', 'تقلب', 'يصر', '😣', 'قدم', 'أغدر', 'يرب', 'اخف', 'بقء', 'منها', 'ء', 'وقع', 'سؤل', 'غية', 'نجز', 'أبعد', 'همم', 'حذر', 'بعثر', 'سئل', 'وكل', 'جد..', 'حقه،', 'لدي', 'مره', 'ندي', 'وعش', 'انه', 'اقل', 'تعب', 'وتر', 'طلع', 'او', 'خرين،', 'ماك', 'خرج', 'دمر', 'جاز', 'غرق', 'طبع', 'عرم', 'كأس', 'مر', 'اصح', '😓', 'جفن', 'امه', 'كسر', ':<', 'حاج', 'عدم', 'أقم', 'عصبب', 'سقط', 'كفو', 'أخر', '١٧', 'اسف', 'ليس', 'لطز', '):<', 'وكأ', 'حمس', '😦', 'هدوء.', 'متوترمحبط', 'حبط', 'ابك', 'طقت', 'قسي', 'شىء', 'هو', 'رضي', ':C', 'جدر', '😭', 'حدث', 'ولا', 'اسي', 'هخخ', 'اشخ', 'ذبذب', 'ببل', 'حرم', 'وفة', 'اصييييييح', 'كوكييز', 'جزء', 'تغلق', 'خير', 'عدل', 'متى', 'ضرر', 'نحل', 'قرب،', 'ليء', 'سرع', 'تجد', 'مع', 'غضب', 'ثمل', ':-/', 'سنن', 'كاف', 'أحلام', 'كبر', 'خرق', 'هالفتر', 'عبء', 'شلع', 'بغى', 'لسب', '😪', 'قدر', 'عقب', 'خفي', 'بلغ', 'وصل', 'يكون', 'سيء', 'صدقائ', 'حيط', 'ادة', '٥', 'قل', 'سهم', 'الى', 'اكن', 'بنت', 'ام', 'تردد', 'على', ';-[', 'لهم', 'هوجاء', 'لصح', 'تحز', 'اخاااااف', 'طيل', ':-(', '😟', 'نكن', 'حي', 'ارض', 'بد.', 'حلي', 'هذا', 'قادرررره', 'عقل', 'إنجاز', 'خلص', 'صمتي،', 'حسي', 'غلب', 'تقي', 'فجع', 'يضء', 'ظني', ':-<', 'جرت', 'غدر', 'تلك', 'ركض', 'رهق', 'سفر', 'نهي', 'نهك', 'طعم', '🥺', 'علم', 'شخص', 'شرح', 'شبع', 'شتق', 'فشل', ':-[', 'وأد', 'شبتر', ':[', 'سر', 'فرط', 'ادف', 'فرق', 'كأن', 'تخذ', 'زقة', ':{', 'أرد', 'ربي', 'انك', 'حسب', 'كرث', 'فرغ', 'قاسية،', 'خسر', 'صعب', 'درس', 'ذنب', 'جلس', 'دمع', 'اتم', 'تهر', 'قبل', 'اني', 'انا', 'جاي', 'شوه', 'غلف', 'حنى', 'وري', 'يمك', 'دهر', ';-(', 'اعجب', 'ومن', 'وسف', 'كما', 'طفئ', 'سيطر', 'هار', 'مرة', 'كل', 'بشء', ';{', 'شعب', 'جسد', 'سخط', 'ففف', 'ادر', 'جبت', '😿', 'حقق', 'واد', 'دقت', 'كمه', 'فوق', '\"عادي\"', 'صلح', 'هلع', '؟؟كيف', 'تمل', 'جمع', 'ؤلم', 'يجب', 'عليل.', 'حيه', 'رعب', 'اقدر', 'عاد', 'عجز', 'جئع', 'عدة', 'حلق', 'ماب', 'دري', 'قرن', 'لست', 'ضلع', 'سبق', 'شي', 'اعط', 'عسى', '😨', 'عتو', 'ورش', 'ضمر', 'سلم', 'غمم', 'بدو', 'وقت', 'زعل', 'بكف', 'جفء', 'تخف', 'فلم', 'صبر', '😴', 'تكر', 'ذار', 'بس', 'سوى', 'بأن', 'ـغرب', 'لغد', 'طفل', '😔', 'خيس', 'حوي', 'عهد', 'غرف', 'طقي', 'دا', 'وعف', 'كمثل', 'كان', 'شعل', 'شيل', 'عزل', 'دون', 'وي', 'قلع', 'ولم', 'هذه', 'سنة', 'رهق،', 'محطممحزن', 'اهخ', 'يفق', 'جهل', 'قلب', 'كمل', 'قتل', 'هجر', 'سمء', 'جزئ', 'وضع', 'أبتلع', '😧', 'ظهر', 'رمضان.', 'يدك', 'ذكر', 'خلق', 'لعن', 'غطه', 'صدع', 'سيئ', 'مايصير', 'نجح', 'حمقى', 'خطى', 'راكم،', 'كمة', 'وحق', 'طن،', 'رهه', 'الي', ':-\\\\', 'كانت', 'حلم', 'انن', 'رجع', 'تحم', 'قاع', ':-C', 'غيهب', 'طقة', 'جاب', 'رسي', 'جدا', 'خبئ', 'نقم', 'ضغط', 'تشت', 'Confused', 'جرح', 'درج', 'انحل', '😥', 'سقم', 'غلط', '؟', 'بعد', 'خوف', 'وجد', 'ذلك', 'سعد', 'هالاسبوع', 'عصف', 'ابي', 'ولكن', 'له', 'يأت', 'يوم', 'القى', '😖', 'لما', 'كتب', 'عطو', 'يطق', ':-{', 'اي', 'برق', 'بدت', 'فضل', 'قلق', 'كلم', 'امر', 'غلق', 'طوه', 'نهر', 'اقد', 'شكل', 'حب', 'مات', ':|', 'انهزامي،', 'اجد', 'صدر', 'جبر', 'ترميييييييننن', 'ضايق', 'صيب', 'نظر', 'ولل', 'اما', 'حين', '☹️', 'مستقبلية', 'بان', 'ريب', 'كئب', 'ايش', 'بهت', 'لأن', 'سمع', ':(', 'لم', ';(', 'تحدث', '.', 'قشعر', 'مال', 'صفر', 'حرب', 'ضيع', 'فرح', '😩', 'احس', 'موت', 'ويش', 'شتت', 'سرب', 'بئر', 'تطل', 'ملأ', 'ثقل', 'جيب', '🙁', 'قوي', 'كر؟', 'قرر', 'نفس', 'هكه', 'عرف', 'رهب', '):', 'حدد', 'فالهزيمة', 'وجه', 'هل', 'علي', '😡', 'ليل', 'يسر', 'طيق', ':c', 'وجا', 'قرب', 'جوع', 'صدق', 'لي', 'ضيق', 'ثق،', 'رغم', 'مواعيد', 'روح', 'يفد', 'نرفز', 'شدد', 'جية', 'رغب', 'دنا', 'صح', 'خبأ', 'ضعف', 'اطلع', 'ختباء،', 'ماض', 'فات', 'حبس', 'انم', 'بيت', 'جدد', 'ضيل.', 'محتجب،', 'كثر', 'وخل', 'فكان', 'الأ', 'اول', 'كذ،', 'حول', 'مش', 'جسم', 'وسن', 'امل', 'ارى', 'عني', 'عند', 'خنق', 'يضببببطططططططط!!!!!!!!', 'ستء', 'غصة', 'ينا', 'عدي', 'يعد', 'ريض', 'خوء', 'تئه', 'عمق', 'عنق', ';-<', 'عطب،', 'و', 'خئب', 'رقق', 'كلة', 'ان', 'شغل', 'حطت', 'بقم', 'كيف', 'خبط', 'صمت', 'ما', 'فين', 'أصل', 'ملي', 'وخب', 'هزل', 'عمة', 'ضرب', 'اكر', '😫', 'لا', 'معي', 'برا', 'بصم', 'ترم', 'خصم', 'جعل', 'حط', 'واستعداد', 'حية', 'هم', 'شيط', 'وسط', 'خدم', 'ارخ', 'قعد', 'كوكيز', 'ومانعارفه', 'حال', ';-/', 'بها', 'نصر', 'زدد', 'قوم', 'بلع', 'الا', 'طول', 'معصصصببة', 'كره', 'خبر', 'رأس', 'عن', 'ارد', 'الم', 'من', 'طيع', ':-c', 'اضي', 'شرع', 'داعي،', 'عيد', 'فكر', 'غرب', 'اسء', 'نقذ', 'حطم', 'حسس', 'رير', '..', 'عنه', 'رجد', 'مني', 'وش', 'فعم', 'شته', 'قيد', 'جنت', 'تحد', 'ضير', 'ابد', 'شيئ', 'خئف', 'ونس', 'بكء', 'غمض', 'يفو', 'تطي', 'رور', 'ايم', 'حزن', 'ايد', 'نهء', 'طرق', 'بين', 'طلب', 'هزم', 'لقى', 'وحد', 'طىء', 'ثانوية،', 'فسق', 'فقد', \":'(\", '😤', 'غفر', 'وزد', 'زجاااج', 'اذا', 'رأت', 'لظل', 'وسع', 'مو', 'احد', 'بحث', ';[', 'بشر', 'اوف', 'شبو', 'هرب', 'بدأ', 'تكئ', 'الل', 'خيب', 'اخذ', 'كله', 'اهل', 'فيه', 'نفذ', 'أنب', 'اثب', 'بدن', 'عرص', 'ضطرب', 'سوء', 'غير', 'أعجز', 'لني', '😢', 'سننجو؟؟؟', 'انهزامية', 'بصح', 'هئل', 'زي', 'نشق', 'مايرتفع', 'ثلث', 'احب', 'طفي', 'خيف', 'غذء', 'دائ', 'خلت', 'عمل', 'وبد', 'أحس', 'وأن', 'نصف', 'علك', 'هناك', 'لكن', 'حيل', 'في', 'متضاييييييييقه', 'نقص', 'طز', 'جوف', 'علق', 'شعر', 'ثقة', 'ردد،', 'انس', 'حزن؟', 'عليها', 'شهر', 'ودع', 'صار', 'ننى', 'حرق', 'خاف', 'سبب', '،', 'وصف', 'رمض', 'بكل', 'اسك', ';-\\\\', 'اقى', 'جمد', 'انت', 'اعز', 'وين', 'اكف', 'شوق', 'ميد', 'توتر', 'خذل', 'لفل', 'باشمئزاز', 'صفح', 'دكتور', 'همة', 'ذلالي!', 'عصب', 'هدي', 'ألف', 'دخل', 'شتم', 'نزع', 'صرخ', 'لن', 'شغف', '😕', 'وما', 'ناس', 'درم', 'كفي', 'زمن', 'بقي', '😠', 'سير', '🙂', 'وضى', 'تحطم', 'عدت', 'حجة', 'ونا', 'يلي', 'اسأ', 'عذب', 'واح', 'زعج', 'رزق', 'هلل', 'ياء', 'ودي', 'لحق', '😾', 'صرف', 'اليوم', 'رحل', 'حمل', 'امن', 'عنف', 'انع', 'تخل', 'قد', 'مب', '😰', 'لنه', 'غلل', '😞', 'شيء', 'امش', 'جنن', 'صحح'}\n"
     ]
    }
   ],
   "source": [
    "new_negative_words = [ \"يؤلم\", \"أسوأ\", \"صعب\", \"صعوبة\",  \"مرير\", \"قاسي\", \"عنيف\", \"عقاب\", \"تعذيب\", \"تشويه\", \"خسارة\", \"استهتار\", \"فاجعة\", \"كارثة\", \"مصيبة\", \"تراجيديا\", \"متعب\", \"متعب\", \"تعبان\", \"تعبان\", \"مجروح\", \"متضايق\", \"متضايق\", \"مكسور\", \"محطم\" \"محزن\",\n",
    "    \"محزن\", \"حزين\", \"منهك\", \"متضايق\",  \"مضطرب\", \"ضيق\", \"ضيق\", \"متوتر\" \"محبط\", \"متحطم\", \"مضطرب\", \"متردد\", \"متردد\", \"مريض\", \"متخوف\", \"مضطرب\", \"متردد\", \"مشتت\", \"غضب\", \"غاضب\", \"مغضوب\", \"غاضب\", \"متضايق\", \"متضايق\", \"متعب\",\n",
    "    \"متعب\", \"متعب\", \"خائب\", \"خائب\", \"مستاء\",  \"مستاء\", \"خائف\", \"خائف\", \"قلق\", \"قلق\",  \"قلق\", \"متوتر\", \"متوتر\", \"متوتر\", \"غاضب\",  \"مغضوب\", \"غضبان\", \"مشتاق\", \"متردد\", \"متوتر\",  \"متردد\", \"متردد\", \"متردد\", \"متردد\", \"متردد\",  \"غاضب\", \"مغضوب\", \"غضبان\", \"مشتاق\", \n",
    "    \"متردد\",\"يؤلم\", \"مؤلم\", \"أسوأ\", \"صعب\", \"صعوبة\", \n",
    "    \"مرير\", \"قاسي\", \"عنيف\", \"عقاب\", \"تعذيب\",  \"تشويه\", \"خسارة\", \"استهتار\", \"فاجعة\", \"كارثة\",  \"مصيبة\", \"تراجيديا\", \"متعب\", \"تعبان\", \"مجروح\",  \"متضايق\", \"مكسور\", \"محطم\", \"محزن\", \"حزين\",\"منهك\", \"مضطرب\", \"ضيق\", \"متوتر\", \"محبط\",\n",
    "    \"متحطم\", \"مضطرب\", \"متردد\", \"مريض\", \"منزعج\", \"متخوف\", \"مشتت\", \"غضب\", \"غاضب\", \"مغضوب\", \"سوء\", \"خائب\", \"مستاء\", \"متردد\", \"غاضب\",\n",
    "    \"مشتاق\", \"متردد\", \"متوتر\", \"متردد\",\"بالإحباط\" ]\n",
    "sad_smileys = [\n",
    "    \":(\", \":'(\", \"):\", \":|\", \":-(\", \"):<\", \":-[\", \":-/\", \":-\\\\\",\n",
    "    \":C\", \":c\", \":-C\", \":-c\", \":-<\", \":-[\", \":-{\", \":(\", \":'(\", \"):\",\n",
    "    \":-(\", \":<\", \":[\", \":{\", \":-[\", \":-{\", \":-[\", \":-\\\\\", \":-/\", \":-[\",\n",
    "    \":-\\\\\", \":-/\", \":(\", \":'(\", \"):\", \":|\", \":-(\", \"):<\", \":-[\", \":-/\", \":-\\\\\",\n",
    "    \":C\", \":c\", \":-C\", \":-c\", \":-<\", \":-[\", \":-{\", \":(\", \":'(\", \"):\",\n",
    "    \":-(\", \":<\", \":[\", \":{\", \":-[\", \":-{\", \":-[\", \":-\\\\\", \":-/\", \":-[\", \":-\\\\\", \":-/\",\n",
    "        \":-(\", \"):\", \";(\", \":'(\", \";-(\", \";-<\", \";-/\", \";-\\\\\", \":-[\", \";[\", \":-<\", \";{\", \";-[\" ,\n",
    "    \"🥺\", \"🙂\",  \"😔\", \"😞\", \"😢\", \"😭\", \"😟\", \"😣\", \"😥\", \"😩\", \"😫\", \"😓\", \"😕\", \"🙁\", \"☹️\", \"😖\", \n",
    "    \"😭\", \"😟\", \"😣\", \"😥\", \"😩\", \"😫\", \"😓\", \"😕\", \"🙁\", \"☹️\", \"😖\",\n",
    "    \"😿\", \"😰\", \"😨\", \"😧\", \"😦\", \"😪\", \"😴\", \"😰\", \"😨\", \"😩\", \"😓\", \"😖\", \"😠\", \"😡\", \"😾\",  \"😤\", \n",
    "]\n",
    "stemmed_negative_words = []\n",
    "for word in new_negative_words:\n",
    "    stemmed_word = arabic_stemmer(word)\n",
    "    stemmed_negative_words.append(stemmed_word)\n",
    "\n",
    "new_negative_words=stemmed_negative_words\n",
    "# print(new_negative_words)\n",
    "negative_words = negative_words.union(new_negative_words)\n",
    "negative_words = negative_words.union(sad_smileys)\n",
    "num_words1 = len(negative_words)\n",
    "print( \" عدد العناصر في المصفوفة negative:\", num_words1)\n",
    "print(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948aafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b04a8c16-846d-477a-a40c-096d50f83bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 الكلمات المشتركة بين positive_words و negative_words: {'درس', 'سعد', 'شرع', 'سوف', 'عيد', 'دمع', 'عصف', 'ولكن', 'قبل', 'قدم', 'ابي', 'له', 'يأت', 'يرب', 'يوم', 'اني', 'كتب', 'انا', '..', 'اي', 'وقع', 'عنه', 'مني', 'غية', 'نجز', 'برق', 'همم', 'فضل', 'كلم', 'امر', 'نهر', 'لدي', 'مره', 'ندي', 'انه', 'حب', 'اقل', 'تعب', 'وتر', 'نظر', 'او', 'من', 'خرج', 'ولل', 'بين', 'جاز', 'كل', 'طبع', 'حين', 'وحد', 'فقد', 'غفر', '😿', 'حقق', 'لم', 'رأت', 'فوق', 'مو', 'فرح', 'جمع', 'احس', 'يجب', 'بشر', 'وكأ', 'حيه', 'الل', 'حمس', 'كله', 'شيء', 'اهل', 'فيه', 'قرر', 'عجز', 'بدن', 'نفس', 'جئع', 'عرف', 'غرب', 'غير', 'شىء', 'هو', 'وجه', 'ولا', 'زي', 'يسر', 'اسي', 'قرب', 'لي', 'شي', 'صدق', 'رغم', 'احب', 'اعط', 'روح', 'ورش', 'عمل', 'سلم', 'شدد', 'وقت', 'وبد', 'سرع', 'دنا', 'رغب', 'علك', 'مع', 'تخف', 'لكن', 'في', 'كبر', 'صبر', 'بيت', 'علق', 'قدر', 'بس', 'جدد', 'شعر', 'بأن', 'خفي', 'كثر', 'لغد', 'ثقة', 'اول', 'وصل', 'حول', 'مش', 'انس', 'حيط', 'امل', 'عند', 'الى', 'عني', 'اكن', 'شهر', 'حرق', 'على', 'سبب', '،', 'عدي', 'لهم', 'كان', 'رمض', 'بكل', 'دون', 'تئه', 'انت', 'عمق', 'هذه', 'شوق', 'و', 'قلب', 'كمل', 'سمء', 'هذا', 'وضع', 'عصب', 'كلة', 'دخل', 'ذكر', 'خلق', 'لن', 'ان', 'شغف', 'خلص', 'غلب', 'ناس', 'نجح', 'خبط', 'ما', 'فين', 'ظني', 'كفي', 'زمن', 'كانت', 'لا', 'معي', '🙂', 'ترم', 'حية', 'حجة', 'ونا', 'انن', 'علم', 'رجع', 'شخص', 'رزق', 'جدا', 'حال', 'ضغط', 'بها', 'نصر', '😾', 'اليوم', 'امن', 'كأن', 'حمل', 'الا', '؟', 'أرد', 'ربي', 'انك', 'بعد', 'عن', 'ارد', 'فرغ', 'وجد', 'فكر', 'خسر', 'ذلك'}\n"
     ]
    }
   ],
   "source": [
    "common_words = positive_words.intersection(negative_words)\n",
    "num_words1 = len(common_words)\n",
    "print(num_words1,\"الكلمات المشتركة بين positive_words و negative_words:\", common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8095290-2ab6-4612-944d-217ff427bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words.difference_update(common_words)\n",
    "negative_words.difference_update(common_words)\n",
    "positive_words=positive_words.union(positive_words)\n",
    "negative_words=positive_words.union(negative_words)\n",
    "# تحديد الكلمات الإيجابية التي توجد في القائمة السلبية\n",
    "list = negative_words.intersection(positive_words)\n",
    "# print(list)\n",
    "\n",
    "# حذف الكلمات الإيجابية من القائمة السلبية\n",
    "negative_words.difference_update(list)\n",
    "num_words = len(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaf16ec7-e5f4-4bb9-af99-0b3971734a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_words= nltk.pos_tag(positive_words)\n",
    "# negative_words= nltk.pos_tag(negative_words)\n",
    "# print(\"عدد العناصر في المصفوفة:\", num_words)\n",
    "# num_words = len(negative_words)\n",
    "# print(\"عدد العناصر في المصفوفة:\", num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db525d56-1c4a-400e-a0e3-d018e24cd1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n",
      "565\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_words))\n",
    "print(len(negative_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af5de7b6-15f1-4c71-a42c-e3cf370494e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ا', 'ل', 'ح', 'ي', 'ا', 'ة', ' ', 'ج', 'م', 'ي', 'ل', 'ة']\n"
     ]
    }
   ],
   "source": [
    "new_comments = [\n",
    "    \"الحياة جميلة\"\n",
    "]\n",
    "#new_comments=new_comments.astype(str)\n",
    "#new_comments=clean_arabic_text(new_comments)\n",
    "#print(new_comments)\n",
    "#for word in new_comments:\n",
    " #   stemmed_word = arabic_stemmer(word)\n",
    "  #  root.append(stemmed_word)\n",
    "\n",
    "new_comments1 = []\n",
    "for word in new_comments:\n",
    "    stemmed_word = clean_arabic_text(word)\n",
    "    stemmed_word = arabic_stemmer(word)\n",
    "    new_comments1.append(stemmed_word)\n",
    "\n",
    "print(new_comments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ca9c130-ce07-4705-bbb2-38539eba6f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "حياة جميلة إيجابي\n"
     ]
    }
   ],
   "source": [
    "for comment in new_comments1:\n",
    "    words = comment.split()  # تقسيم التعليق إلى كلمات\n",
    "    positive_count = sum(word in positive_words for word in words)\n",
    "    negative_count = sum(word in negative_words for word in words)\n",
    "    print(positive_count,negative_count)    \n",
    "    if positive_count >= negative_count:\n",
    "        print(comment, \"إيجابي\")\n",
    "    elif positive_count < negative_count:\n",
    "        print(comment, \"سلبي\")\n",
    "    else:\n",
    "        print(comment, \"محايد\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2f9a3a3-db86-4a24-b5f9-8bc83780636d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIMDBar.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data1 \u001b[38;5;241m=\u001b[39m data1\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m      3\u001b[0m data1\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\FawziaIssa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FawziaIssa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\FawziaIssa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\FawziaIssa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('IMDBar.csv', delimiter=';')\n",
    "data1 = data1.astype(str)\n",
    "data1.replace({'sentiment': {'negative': 0}}, inplace=True)\n",
    "data1.replace({'sentiment': {'positive': 1}}, inplace=True)\n",
    "# data.drop(columns=[0], inplace=True)\n",
    "data1 = data1.iloc[:3000]\n",
    "data_clear=data1\n",
    "data_clear['After_Preprocessing'] = data1['review'].apply(clean_arabic_text)\n",
    "print(data_clear['After_Preprocessing'].iloc[:4])\n",
    "data_clear['After_Preprocessing'] = data_clear['After_Preprocessing'].apply(lambda x: [arabic_stemmer(word) for word in x])\n",
    "print(data_clear['After_Preprocessing'].iloc[:4])\n",
    "data1=data_clear\n",
    "# data1.iloc[:, 1] = data1.iloc[:, 1].apply(arabic_stemmer)\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdaddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "num_rows,mum_col=data1.shape\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lval= data1['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126743af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy%: 100.0\n"
     ]
    }
   ],
   "source": [
    "sum_acc = 0\n",
    "for idx, comment in enumerate(data1.iloc[:, 2]):  # تكرار عبر الصفوف مع الحصول على فهرس الصف\n",
    "    # words = comment.split()\n",
    "    # words = nltk.pos_tag(words)\n",
    "    positive_total = sum(word[0] in positive_words for word in comment if word[1].startswith('NN') or word[1].startswith('VB'))\n",
    "    negative_total = sum(word[0] in negative_words for word in comment if word[1].startswith('NN') or word[1].startswith('VB'))\n",
    "    # print(positive_total, negative_total)\n",
    "    if positive_total >= negative_total:\n",
    "        statement = 1\n",
    "        if data1.iloc[idx, 0] == 1:  # الوصول إلى القيمة في العمود الثاني للصف المحدد\n",
    "            sum_acc += 1\n",
    "    elif positive_total < negative_total:\n",
    "        statement = 0\n",
    "        if data1.iloc[idx, 0] == 0:  # الوصول إلى القيمة في العمود الثاني للصف المحدد\n",
    "            sum_acc += 1\n",
    "    if contains_negative_words == False:\n",
    "        if positive_total < negative_total:\n",
    "            statement = 1\n",
    "        if data1.iloc[idx, 0] == 1:  # الوصول إلى القيمة في العمود الثاني للصف المحدد\n",
    "            sum_acc += 1\n",
    "    elif positive_total >= negative_total:\n",
    "        statement = 0\n",
    "        if data1.iloc[idx, 0] == 0:  # الوصول إلى القيمة في العمود الثاني للصف المحدد\n",
    "            sum_acc += 1\n",
    "\n",
    "accuracy = sum_acc / len(data1) \n",
    "print(\"Accuracy%:\",accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a06284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
